"""
å¯¹è¯æ¨¡å¼æ ‡ç­¾é¡µ
åŠŸèƒ½ï¼šé€šè¿‡è‡ªç„¶è¯­è¨€å¯¹è¯æ–¹å¼ä¸‹æ£‹å’Œåˆ†æ
"""

import gradio as gr
import json
import os
import chess
from sessions.manager import session_manager
from llm.client import llm_client
from llm.tools import tools
from llm.prompts import get_analysis_prompt
from ui.components import render_board
from chess_core.engine import get_engine


def process_chat_message(message, session_id="default"):
    """
    å¤„ç†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è¾“å…¥
    è¿”å›æœºå™¨äººå›å¤
    """
    if not message or message.strip() == "":
        return "è¯·è¾“å…¥æ¶ˆæ¯..."
    
    # è·å–ä¼šè¯
    session = session_manager.get_session(session_id)
    current_fen = session.board.fen()
    current_turn = "ç™½æ–¹" if session.board.turn == chess.WHITE else "é»‘æ–¹"
    
    try:
        # è°ƒç”¨OpenAIè§£æç”¨æˆ·æ„å›¾
        response = llm_client.chat_completion(
            messages=[
                {"role": "system", "content": f"""
                ä½ æ˜¯ä¸€ä¸ªå›½é™…è±¡æ£‹åŠ©æ‰‹ã€‚å½“å‰æ£‹ç›˜FEN: {current_fen}
                è½®åˆ°ï¼š{current_turn}
                èµ°æ³•å†å²ï¼š{session.get_status()['history']}
                
                ä½ çš„ä»»åŠ¡ï¼š
                1. å¦‚æœç”¨æˆ·æè¿°äº†ä¸€ä¸ªèµ°æ³•ï¼ˆå¦‚"æˆ‘èµ°e4"ï¼‰ï¼Œè°ƒç”¨ make_move
                2. å¦‚æœç”¨æˆ·é—®å…³äºå±€åŠ¿çš„é—®é¢˜ï¼ˆå¦‚"è°ä¼˜åŠ¿"ï¼‰ï¼Œè°ƒç”¨ analyze_position
                3. å¦‚æœç”¨æˆ·æƒ³é‡æ–°å¼€å§‹ï¼Œè°ƒç”¨ reset_board
                4. å¦‚æœç”¨æˆ·æè¿°å¤šä¸ªèµ°æ³•ï¼Œä¾æ¬¡è°ƒç”¨ make_move
                
                ç”¨å‹å¥½çš„è¯­æ°”å›å¤ï¼Œè§£é‡Šä½ åšäº†ä»€ä¹ˆã€‚
                """},
                {"role": "user", "content": message}
            ],
            tools=tools
        )
        
        response_message = response.choices[0].message
        
        # å¤„ç†å‡½æ•°è°ƒç”¨
        if response_message.tool_calls:
            results = []
            
            for tool_call in response_message.tool_calls:
                function_name = tool_call.function.name
                function_args = json.loads(tool_call.function.arguments) if tool_call.function.arguments else {}
                
                # æ‰§è¡Œå¯¹åº”çš„å‡½æ•°
                if function_name == "make_move":
                    result = session.make_move(function_args["move"])
                    results.append(result)
                    
                elif function_name == "analyze_position":
                    # è°ƒç”¨å¼•æ“åˆ†æ
                    engine = get_engine()
                    engine_result = engine.analyze_position(session.board.fen())
                    session.last_analysis = engine_result
                    results.append(engine_result)
                    
                elif function_name == "reset_board":
                    result = session.reset()
                    results.append({"message": result["message"]})
                    
                elif function_name == "get_move_history":
                    history = session.get_move_history()
                    results.append({"history": history})
                    
                elif function_name == "explain_position":
                    results.append({"message": "æ­£åœ¨åˆ†æå±€åŠ¿..."})
            
            # ç”Ÿæˆè‡ªç„¶è¯­è¨€å›å¤
            return generate_chat_response(message, session, results)
        else:
            # æ²¡æœ‰å‡½æ•°è°ƒç”¨ï¼Œå¯èƒ½æ˜¯æ™®é€šå¯¹è¯
            return handle_general_chat(message, session)
            
    except Exception as e:
        return f"å¤„ç†å‡ºé”™: {str(e)}ã€‚è¯·é‡è¯•ã€‚"


def generate_chat_response(original_message, session, results):
    """ç”Ÿæˆè‡ªç„¶è¯­è¨€å›å¤"""
    status = session.get_status()
    
    # æ„å»ºå›å¤æç¤ºè¯
    prompt = get_analysis_prompt(original_message, status, results)
    
    try:
        response = llm_client.chat_completion(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯å›½é™…è±¡æ£‹åŠ©æ‰‹ï¼Œè¯­æ°”å‹å¥½ä¸“ä¸šã€‚"},
                {"role": "user", "content": prompt}
            ],
            model=os.getenv("OPENAI_MODEL_CHEAP", "gpt-3.5-turbo"),
            temperature=0.5,
            max_tokens=300
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        # é™çº§å›å¤
        if results and "best_move" in results[0]:
            r = results[0]
            return f"åˆ†æå®Œæˆï¼æ¨èèµ°æ³•ï¼š{r['best_move']}ï¼Œè¯„ä¼°ï¼š{r['evaluation']}ã€‚å½“å‰{status['status']}ï¼Œè½®åˆ°{status['turn']}ã€‚"
        elif results and "move" in results[0] and results[0].get("success"):
            return f"å·²è®°å½• {results[0]['move']}ã€‚å½“å‰{status['status']}ï¼Œè½®åˆ°{status['turn']}ã€‚"
        else:
            return f"å½“å‰è½®åˆ°{status['turn']}ï¼Œ{status['status']}ã€‚ä½ æƒ³æ€ä¹ˆèµ°ï¼Ÿ"


def handle_general_chat(message, session):
    """å¤„ç†æ™®é€šå¯¹è¯ï¼ˆæ²¡æœ‰å‡½æ•°è°ƒç”¨ï¼‰"""
    status = session.get_status()
    
    prompt = f"""
    ç”¨æˆ·è¯´ï¼š{message}
    
    å½“å‰æ£‹ç›˜çŠ¶æ€ï¼š
    - è½®åˆ°ï¼š{status['turn']}
    - çŠ¶æ€ï¼š{status['status']}
    - èµ°æ³•å†å²ï¼š{status['history']}
    
    è¯·ä»¥å›½é™…è±¡æ£‹åŠ©æ‰‹çš„èº«ä»½å‹å¥½å›å¤ã€‚å¯ä»¥ï¼š
    - å¦‚æœç”¨æˆ·é—®é—®é¢˜ï¼Œå›ç­”å›½é™…è±¡æ£‹ç›¸å…³çŸ¥è¯†
    - å¦‚æœç”¨æˆ·æ²¡æŒ‡å®šåŠ¨ä½œï¼Œè¯¢é—®æ˜¯æƒ³èµ°æ£‹è¿˜æ˜¯åˆ†æ
    - ä¿æŒå¯¹è¯è‡ªç„¶
    """
    
    try:
        response = llm_client.chat_completion(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯å›½é™…è±¡æ£‹åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            model="gpt-3.5-turbo",
            temperature=0.7,
            max_tokens=200
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"å½“å‰è½®åˆ°{status['turn']}ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ çš„èµ°æ³•ã€‚"


def create_chat_tab():
    """
    åˆ›å»ºå¯¹è¯æ¨¡å¼æ ‡ç­¾é¡µ
    """
    with gr.TabItem("ğŸ’¬ AIå¯¹è¯æ¨¡å¼"):
        gr.Markdown("""
        ### ğŸ¯ åƒèŠå¤©ä¸€æ ·ä¸‹æ£‹ï¼
        
        **å®Œå…¨ä¸ç”¨è¾“å…¥FEN**ï¼Œç›´æ¥æè¿°ä½ çš„èµ°æ³•ï¼š
        - **èµ°æ£‹**ï¼š"æˆ‘èµ°e4"ã€"å¯¹æ‰‹e5"ã€"æˆ‘Nf3ï¼Œå¯¹æ‰‹Nc6"
        - **åˆ†æ**ï¼š"ç°åœ¨è°ä¼˜åŠ¿ï¼Ÿ"ã€"åˆ†æå½“å‰å±€é¢"
        - **é‡ç½®**ï¼š"æˆ‘æƒ³é‡æ–°å¼€å§‹ä¸€å±€"
        """)
        
        # ä¼šè¯çŠ¶æ€
        session_id = gr.State("default")
        
        with gr.Row():
            # å·¦ä¾§ï¼šæ£‹ç›˜å’Œä¿¡æ¯
            with gr.Column(scale=1):
                # æ£‹ç›˜æ˜¾ç¤º
                chat_board = gr.HTML(
                    label="å½“å‰æ£‹ç›˜",
                    value=render_board("rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1")
                )
                
                # æ£‹ç›˜çŠ¶æ€ä¿¡æ¯
                with gr.Group():
                    gr.Markdown("### ğŸ“Š å½“å‰çŠ¶æ€")
                    
                    with gr.Row():
                        chat_turn = gr.Textbox(
                            label="è½®åˆ°",
                            interactive=False,
                            value="ç™½æ–¹",
                            scale=1
                        )
                        chat_status = gr.Textbox(
                            label="çŠ¶æ€",
                            interactive=False,
                            value="æ­£å¸¸å¯¹å±€",
                            scale=2
                        )
                    
                    chat_fen = gr.Textbox(
                        label="FEN",
                        interactive=False,
                        lines=2,
                        value="rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1"
                    )
                    
                    chat_history_moves = gr.Textbox(
                        label="èµ°æ³•å†å²",
                        interactive=False,
                        lines=2,
                        value="æ— "
                    )
                    
                    with gr.Row():
                        material_balance = gr.Textbox(
                            label="å­åŠ›å¯¹æ¯”",
                            interactive=False,
                            value="ç™½æ–¹ 39 - 39 é»‘æ–¹"
                        )
                        legal_moves = gr.Textbox(
                            label="åˆæ³•èµ°æ³•",
                            interactive=False,
                            value="20"
                        )
            
            # å³ä¾§ï¼šå¯¹è¯åŒºåŸŸ
            with gr.Column(scale=1):
                chatbot = gr.Chatbot(
                    label="å¯¹è¯è®°å½•",
                    height=450,
                    bubble_full_width=False
                )
                
                with gr.Row():
                    msg = gr.Textbox(
                        label="ä½ çš„æ¶ˆæ¯",
                        placeholder="ä¾‹å¦‚ï¼šæˆ‘èµ°e4 / è°ä¼˜åŠ¿ï¼Ÿ / é‡æ–°å¼€å§‹",
                        lines=2,
                        scale=8
                    )
                    send_btn = gr.Button(
                        "å‘é€",
                        variant="primary",
                        scale=1,
                        min_width=80
                    )
                
                with gr.Row():
                    clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", size="sm")
                    reset_btn = gr.Button("ğŸ”„ é‡ç½®æ£‹ç›˜", size="sm", variant="secondary")
                    analyze_btn = gr.Button("ğŸ“Š åˆ†æå½“å‰", size="sm", variant="secondary")
        
        # å¿«æ·è¾“å…¥ç¤ºä¾‹
        gr.Markdown("### ğŸ“ å¿«æ·è¾“å…¥")
        
        examples = [
            ["å¼€å±€e4", "æˆ‘èµ°e4"],
            ["å¯¹æ‰‹å›åº”", "å¯¹æ‰‹e5"],
            ["å‡ºåŠ¨é©¬", "æˆ‘Nf3"],
            ["å¯¹æ‰‹å‡ºé©¬", "å¯¹æ‰‹Nc6"],
            ["è°ä¼˜åŠ¿", "ç°åœ¨è°ä¼˜åŠ¿ï¼Ÿ"],
            ["åˆ†æ", "åˆ†æå½“å‰å±€é¢"],
            ["é‡ç½®", "æˆ‘æƒ³é‡æ–°å¼€å§‹"],
            ["èµ°æ³•å†å²", "åˆšæ‰æ€ä¹ˆèµ°çš„ï¼Ÿ"]
        ]
        
        # åˆ›å»ºå¿«æ·æŒ‰é’®
        with gr.Row():
            for i in range(0, len(examples), 4):
                with gr.Column():
                    for desc, example in examples[i:i+4]:
                        gr.Button(f"ğŸ“Œ {desc}", size="sm").click(
                            lambda e=example: e,
                            None,
                            msg
                        )
        
        # å‡½æ•°å®šä¹‰
        def update_chat_display(session_id):
            """æ›´æ–°æ£‹ç›˜æ˜¾ç¤ºå’Œä¿¡æ¯"""
            session = session_manager.get_session(session_id)
            status = session.get_status()
            return (
                render_board(status["fen"]),
                status["turn"],
                status["status"],
                status["fen"],
                status["history"],
                f"ç™½æ–¹ {status['white_piece_value']} - {status['black_piece_value']} é»‘æ–¹",
                str(status["legal_moves"])
            )
        
        def chat_respond(message, history, session_id):
            """å¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶æ›´æ–°ç•Œé¢"""
            if not message or message.strip() == "":
                return "", history, session_id
            
            # è·å–æœºå™¨äººå›å¤
            bot_message = process_chat_message(message, session_id)
            
            # æ›´æ–°å¯¹è¯å†å²
            history.append((message, bot_message))
            
            # æ›´æ–°æ˜¾ç¤º
            board_html, turn, status, fen, moves, material, legal = update_chat_display(session_id)
            
            return "", history, session_id, board_html, turn, status, fen, moves, material, legal
        
        def reset_chat(session_id):
            """é‡ç½®æ£‹ç›˜"""
            session = session_manager.get_session(session_id)
            session.reset()
            return update_chat_display(session_id)
        
        def analyze_current(session_id):
            """åˆ†æå½“å‰å±€é¢"""
            session = session_manager.get_session(session_id)
            bot_message = process_chat_message("åˆ†æå½“å‰å±€é¢", session_id)
            
            # è·å–å½“å‰å¯¹è¯å†å²
            current_history = chatbot.value or []
            current_history.append(("åˆ†æå½“å‰å±€é¢", bot_message))
            
            # æ›´æ–°æ˜¾ç¤º
            board_html, turn, status, fen, moves, material, legal = update_chat_display(session_id)
            
            return current_history, board_html, turn, status, fen, moves, material, legal
        
        # äº‹ä»¶ç»‘å®š
        msg.submit(
            chat_respond,
            [msg, chatbot, session_id],
            [msg, chatbot, session_id, chat_board, chat_turn, chat_status, 
             chat_fen, chat_history_moves, material_balance, legal_moves]
        )
        
        send_btn.click(
            chat_respond,
            [msg, chatbot, session_id],
            [msg, chatbot, session_id, chat_board, chat_turn, chat_status, 
             chat_fen, chat_history_moves, material_balance, legal_moves]
        )
        
        reset_btn.click(
            reset_chat,
            [session_id],
            [chat_board, chat_turn, chat_status, chat_fen, 
             chat_history_moves, material_balance, legal_moves]
        ).then(
            lambda: ("ç³»ç»Ÿï¼šæ£‹ç›˜å·²é‡ç½®", None),
            None,
            [msg, chatbot],
            queue=False
        )
        
        analyze_btn.click(
            analyze_current,
            [session_id],
            [chatbot, chat_board, chat_turn, chat_status, chat_fen, 
             chat_history_moves, material_balance, legal_moves]
        )
        
        clear_btn.click(
            lambda: None,
            None,
            chatbot,
            queue=False
        )
        
        # åˆå§‹åŠ è½½
        demo.load(
            update_chat_display,
            [session_id],
            [chat_board, chat_turn, chat_status, chat_fen, 
             chat_history_moves, material_balance, legal_moves]
        )
        
        # å¸®åŠ©ä¿¡æ¯
        with gr.Accordion("â“ ä½¿ç”¨è¯´æ˜", open=False):
            gr.Markdown("""
            ### å¦‚ä½•ä½¿ç”¨AIå¯¹è¯æ¨¡å¼
            
            **åŸºæœ¬æ“ä½œï¼š**
            1. åœ¨è¾“å…¥æ¡†æè¿°ä½ çš„èµ°æ³•ï¼Œæ¯”å¦‚"æˆ‘èµ°e4"
            2. AIä¼šè‡ªåŠ¨æ›´æ–°æ£‹ç›˜å¹¶å›å¤
            3. ç»§ç»­æè¿°å¯¹æ‰‹çš„èµ°æ³•ï¼š"å¯¹æ‰‹e5"
            4. éšæ—¶å¯ä»¥é—®ï¼š"è°ä¼˜åŠ¿ï¼Ÿ"æˆ–"åˆ†æä¸€ä¸‹"
            
            **æ”¯æŒçš„æŒ‡ä»¤ï¼š**
            - **èµ°æ£‹**ï¼š"æˆ‘èµ°[èµ°æ³•]"ï¼Œ"å¯¹æ‰‹[èµ°æ³•]"
            - **åˆ†æ**ï¼š"è°ä¼˜åŠ¿ï¼Ÿ"ï¼Œ"åˆ†æå±€é¢"ï¼Œ"æ€ä¹ˆèµ°ï¼Ÿ"
            - **é‡ç½®**ï¼š"é‡æ–°å¼€å§‹"ï¼Œ"æ–°çš„ä¸€å±€"
            
            **èµ°æ³•æ ¼å¼ï¼š**
            - å…µï¼še4, d5, exd5ï¼ˆåƒå­ï¼‰
            - é©¬ï¼šNf3, Nc6
            - è±¡ï¼šBb5, Bg4
            - è½¦ï¼šRe1
            - åï¼šQe2
            - ç‹ï¼šO-Oï¼ˆçŸ­æ˜“ä½ï¼‰ï¼ŒO-O-Oï¼ˆé•¿æ˜“ä½ï¼‰
            
            **æŠ€å·§ï¼š**
            - å¯ä»¥ä¸€æ¬¡æè¿°å¤šä¸ªèµ°æ³•ï¼Œå¦‚"æˆ‘èµ°e4ï¼Œå¯¹æ‰‹e5ï¼Œæˆ‘Nf3"
            - ä¸ç¡®å®šèµ°æ³•åç§°æ—¶ï¼Œå¯ä»¥ç”¨è‡ªç„¶è¯­è¨€æè¿°
            """)
    
    return {
        "session_id": session_id,
        "chatbot": chatbot,
        "msg": msg,
        "chat_board": chat_board,
        "chat_turn": chat_turn,
        "chat_status": chat_status,
        "chat_fen": chat_fen,
        "chat_history_moves": chat_history_moves
    }